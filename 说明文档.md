# 司法数据分析说明文档

[TOC]



## 1代码文件介绍

### 1.1工具版本

| Python        | **3.6**     |
| ------------- | ----------- |
| **Django**    | **3.2.10**  |
| **Gensim**    | **4.1.2**   |
| **jieba**     | **0.42.1**  |
| **pyltp**     | **0.2.1**   |
| **pyperclip** | **1.8.2**   |
| **PyAutoGUI** | **0.9.53**  |
| **selenium**  | **3.141.0** |

### 1.2**项目结构**

```python
djangoProject1
│  .gitignore.txt
│  chromedriver.exe
│  crf_learn.exe
│  database.db		   #数据库
│  crf_test.exe        #crf测试方法
│  database_process.py #数据库处理
│  feature.py          #crf提取特征要素
│  get_data.py         #crf总方法
│  libcrfpp.dll
│  ltp_true.py         #分词
│  model               #模型文件
│  output1             #训练文件
│  result              #训练结果
│  template01          #crf模型文件
│  manage.py
│  utils.p
│  views.py
│  __init__.py
│
├─.idea
│
├─__pycache__
│
├─APP1					#爬虫
│
├─APP2					#分词
│
├─APP3					#保存标注
│
├─APP4					#相似案例
│
├─appHTML				#前端
│
├─djangoProject1		#总路径
│
├─HTML					#前端代码
│
├─Lib					
│
├─Scripts
│
├─templates
│
├─word2evc				 #工具包
│
├─分词					#工具包
│
└─特征提取				   #工具包	
```

### 1.3整体框架

本项目采用Django作为Web框架, 为APP1-APP4，以及appHTML（前端页面）分配url路径，以实现前后端数据传递。运行时需要先启动Django项目，默认地址为http://127.0.0.1:8000/。

```python
项目子文件夹djangoProject1
│  asgi.py
│  settings.py
│  urls.py    #各项目url路径汇总
│  wsgi.py
│  __init__.py
│
└─__pycache__
```

urls.py

```python
from django.contrib import admin
from django.urls import path, include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('APP1/', include('APP1.urls')),    #爬虫
    path('APP2/', include('APP2.urls')),     #分词
    path('APP3/', include('APP3.urls')),     #保存标注
    path('APP4/', include('APP4.urls')),     #相似案例
    path('appHTML/', include('appHTML.urls')),   #前端页面
]
```

#### 1.3.1后端实现

这里以APP3（功能保存案件标注）为例，其他子项目与此类似。

```python
APP3
│  admin.py
│  apps.py
│  models.py
│  tests.py
│  urls.py    #APP3的url路径
│  views.py   #视图函数，接受请求并响应，执行相应功能
│  __init__.py
│
├─migrations
│      __init__.py
│
└─__pycache__
```

urls.py

```python
from django.urls import path
from . import views

urlpatterns=[
    path('', views.fun)
]
```

views.py

```python
from django.http import JsonResponse
import json
import os

def fun(request):
    #......省略，以Json文件保存标注至本地
    return JsonResponse({"path": path})
```

当前端(路径：http://localhost:8000/appHTML/)相应事件触发时，发送数据传输请求到http://localhost:8000/APP3/时，执行fun函数里的内容，返回文件夹的路径给前端, 前端再将其展示在页面上。

#### 1.3.2前端实现

```javascript
$.ajax({
    url: 'http://localhost:8000/APP3/',
    type: 'post',
    data: JSON.stringify($(jsonLabel)),
    dataType: 'json',
    contentType: 'application/json',
    success: function (data){
        alert("保存成功！文件已保存至"+data.path);
    },
    error: function () {
        alert("error");
    }
})
```

这里采用Ajax异步请求，前后端交互不需要刷新页面，代码为Jquery,整洁美观。

### 1.4功能介绍

#### 1.4.1爬虫工具

##### 目录

```python
APP1
│  admin.py
│  apps.py
│  crf_test.exe。      #crf测试方法
│  database_process.py #数据库处理
│  feature.py          #crf提取特征要素
│  get_data.py         #crf总方法
│  libcrfpp.dll
│  ltp_true.py         #分词
│  model               #模型文件
│  models.py
│  nlp_method.py       #分词总方法
│  output1             #训练文件
│  result              #训练结果
│  template01          #crf模型文件
│  urls.py			   #url路径
│  utils.py
│  views.py			   #视图函数
│  __init__.py
│
├─.idea
│  │  .gitignore
│  │  misc.xml
│  │  modules.xml
│  │  workspace.xml
│  │  特征提取.iml
│  │
│  └─inspectionProfiles
│          profiles_settings.xml
│
├─migrations
│
├─static			   #静态文件夹，存放静态文件
│
└─__pycache__
```

##### 作用

得到前端页面传来时间，关键词，和数量，建立与数据库的连接，如果数据库中有足够数量的案件，则从数据库中取出案件保存至本地，若数据库中文书数量不足，则自动从文书网下载到数据库，再保存至本地。案件文书放入数据库时进行crf特征要素提取，计算向量、分词结果和特征要素并存入数据库，为之后的流程中寻找相似案例提供参考。

##### 关键代码

feature.py

```python
from 特征提取 import utils

def remove_duplicate_elements(l):	# 去除列表中重复元素，同时保持相对顺序不变

def func(file_name):	# 将属于同一事件要素的词语合并
    
def get_patterns_from_dict(event_elements):		#将提取出的事件要素转换成特征
    
def feature(filename):		#传入文件，返回特征要素
    
```

views.py

```python
def fun(request):	#前后端交互
    
def databaseEntry(path,word):	#数据库处理
    
def Rep(startTime,endTime,num,word):
    # 传入参数,并创建一个子文件夹用于存放下载数据
    
    connection = sqlite3.connect('D:\\DATA SCIENCE\\djangoProject1\\database.db')  #创建与数据库的连接
    cur = connection.cursor()	#创建一个游标
    
    if length>=num:		# 若数据库中有足够的文书，那么可以直接从数据库中取并保存到本地
        for i in range(0,num):
            title = titles[i][0] + '.txt'
            content = contents[i][0]
            thisPath = os.path.join(filename,title)
            file = open(thisPath,'w')
            file.write(content)
    else:	# 数据库中文书数量不足，直接从文书网下载
        download(startTime,endTime,num,word)
        sleep(15)	# 等待下载
        fileProcess('D:\数据科学爬取案件\\',filename,word)
```

#### 1.4.2分词方法

##### 目录

```python
APP2
│  admin.py
│  apps.py
│  models.py
│  nlp_method.py	#分词方法
│  result			
│  test
│  tests.py
│  urls.py			#路径
│  views.py			#视图
│  __init__.py
│
├─migrations
│
├─nlp
│
└─__pycache__
```

##### 作用

接收前端传来的案件内容，采用多种分词方式进行分词标注和特征要素提取，将结果返回前端。

##### 关键代码

views.py

```python
def fun(request):	
    
    jsonDict = nlp_method.cut(text)
    dict_feature, pattern = get_data.word_process_text(text)
    result_dict = {					#type: 嵌套字典
        "cut": jsonDict,			#分词标注
        "feature": dict_feature		#特征要素
    }
    return JsonResponse(result_dict)
```

nlp_method.py

```python
def cut(content):     #总分词方法
    
def ltp_cut(content):	#中文分词
def ltp_pos(words):		#词性标注
def dict_wordpos(words,postags):		#生成分词和词性的字典
def delete_POS(words,postags,list):		#在字典中删掉固定词性的词语
def select_POS(words,postags,list):		#筛选制定词性的词语
	
def find_all(list,dict):					#找出所有指定属性的词语
def find_continuous(list,words,postags):	#找到连续的指定词语词语
def remove_repeat(continuous_list):			#去掉重复的词语

def ltp_net(words,postags):			#命名实体识别
def dict_wordnet(words,postags):	#生成命名实体字典
def get_net(list,words,postags):	#实体识别某些特定的属性
def stopwords():					# 加入停用词库
def self_dic():						# 加入自定义词典
def jieba_exact(content, filepath3):	# jieba分词精确模式
def jieba_pos(content):					# jieba词性标注
def tfidf(content, topK, withWeight, list):			# 基于tfidf算法的关键词提取
def textrank(content, topK, withWeight, list):		# 基于textrank算法的关键词提取
def get_pos(content, pos):							# 获得对应属性的分词
```

#### 1.4.3标注保存

即APP3，前后端交互中以之为例，在此不再赘述。

#### 1.4.4相似分析

##### 目录

```python
APP4
│  admin.py
│  apps.py
│  models.py
│  tests.py
│  urls.py
│  views.py
│  __init__.py
│
├─migrations
│
└─__pycache__
```

##### 作用

接受前端传来的关键词和文本内容，计算出向量，与数据库中相关案例的向量进行比对，从数据库中取出相似度最高的案件返回给前端。

##### 关键代码

views.py

```python
def find_max(searchword,text):		# 找到最大相似度的案件
    """
    :param searchword（即爬虫时用户输入的搜索关键词word
           text（前端传过来的需要寻找相似案件的文书）
    :return: 返回一个列表，第0个元素是标题，第1个元素是正文内容
    """
    # 遍历数据库 得到每个案件的向量
    # 用vector——similarity方法算出最大值
    # 取出对应案件
```

#### 1.4.5前端页面

##### 目录

```python
appHTML
│  admin.py
│  apps.py
│  models.py
│  tests.py
│  urls.py
│  views.py
│  __init__.py
│
├─migrations
│
└─__pycache__
```

```python
HTML
│  htmlfile.html	#前端代码文件
```

##### 作用

html+CSS+JavaScript编写。用户在此页面发送请求，提交数据。展示分词结果，相似案例。

##### 关键代码

htmlfile.html

```html
<script src={% static 'Jquery/jquery-3.3.0.min.js' %}></script>		<!--引入Jqurey文件-->
<script>
	function change(temp)			
	function change_extra(temp)		//切换栏切换
	function FileWord(files)		//将上传的文件内容显示在文本框中
	$(document).ready(function ())		//页面加载完后绑定监听事件，实现前后端交互
</script>	
```

## 2注意事项

### 2.1版本兼容

建议所有工具版本一律与代码文件介绍中所列版本一致，不要使用过新版本的工具，易出现兼容问题。导入的包均需导入到项目所在虚拟环境下。

### 2.2文件目录

项目内容较多，文件引用、方法调用比较丰富，静态文件夹内容十分重要，该说明里所有目录仅选取较为关键的内容进行展示。为了防止大片报错，建议不要随意删除文件里任何内容！

### 2.3本地地址

本项目编写过程中运行地址为D:\DATA SCIENCE\djangoProject1，运行中涉及到其中一些工具调用的路径，另外，爬虫工具得到的案件位于D:\数据科学爬取案件，案件标注保存的地址为D:\数据科学爬取案件\案件标注文件夹，建议运行时创建相同的文件夹，或者对相应地址进行修改，否则可能会出现错误。

### 2.4网络卡顿

由于裁判文书网网络卡顿，爬虫工具在下载文书时可能会出现等待事件较长，甚至爬取失败等现象，请耐心等待，或网络通畅时重新在前端点击运行程序。

## 3版权声明

本项目仅用于南京大学数据科学大作业提交，不用于任何商业用途。